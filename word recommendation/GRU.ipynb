{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a757ef0",
   "metadata": {},
   "source": [
    "#### Dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c0a9428",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Dense,LSTM,GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf942466",
   "metadata": {},
   "source": [
    "#### Creating our Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcaff0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"words.txt\",\"r\") as file:\n",
    "    text=file.read()"
   ]
  },

  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4199bd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_len=len(text)\n",
    "indx=[]\n",
    "for i in range(w_len):\n",
    "    if text[i]==\".\":\n",
    "        indx.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b06bc68",
   "metadata": {},
   "source": [
    "Extracting sentence from given text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3012b05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence=[]\n",
    "j=0\n",
    "for ind in indx:\n",
    "    sen=text[j:ind]\n",
    "    sentence.append(sen)\n",
    "    j=ind+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a13a9a90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Others prepared their work for the day and tried to keep a steady pace so they would not feel tired'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea8f930a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a0c8b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts([text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2447eeef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 1,\n",
       " 'and': 2,\n",
       " 'a': 3,\n",
       " 'to': 4,\n",
       " 'people': 5,\n",
       " 'day': 6,\n",
       " 'of': 7,\n",
       " 'in': 8,\n",
       " 'their': 9,\n",
       " 'they': 10,\n",
       " 'made': 11,\n",
       " 'air': 12,\n",
       " 'slow': 13,\n",
       " 'light': 14,\n",
       " 'simple': 15,\n",
       " 'steady': 16,\n",
       " 'this': 17,\n",
       " 'small': 18,\n",
       " 'calm': 19,\n",
       " 'felt': 20,\n",
       " 'when': 21,\n",
       " 'some': 22,\n",
       " 'feel': 23,\n",
       " 'was': 24,\n",
       " 'moved': 25,\n",
       " 'soft': 26,\n",
       " 'with': 27,\n",
       " 'from': 28,\n",
       " 'sky': 29,\n",
       " 'sound': 30,\n",
       " 'every': 31,\n",
       " 'sat': 32,\n",
       " 'on': 33,\n",
       " 'quiet': 34,\n",
       " 'or': 35,\n",
       " 'warm': 36,\n",
       " 'it': 37,\n",
       " 'open': 38,\n",
       " 'many': 39,\n",
       " 'liked': 40,\n",
       " 'life': 41,\n",
       " 'easy': 42,\n",
       " 'came': 43,\n",
       " 'clear': 44,\n",
       " 'smooth': 45,\n",
       " 'one': 46,\n",
       " 'another': 47,\n",
       " 'rhythm': 48,\n",
       " 'bright': 49,\n",
       " 'joy': 50,\n",
       " 'like': 51,\n",
       " 'stream': 52,\n",
       " 'way': 53,\n",
       " 'place': 54,\n",
       " 'walked': 55,\n",
       " 'touched': 56,\n",
       " 'ground': 57,\n",
       " 'wind': 58,\n",
       " 'carried': 59,\n",
       " 'gentle': 60,\n",
       " 'as': 61,\n",
       " 'space': 62,\n",
       " 'here': 63,\n",
       " 'each': 64,\n",
       " 'spread': 65,\n",
       " 'fields': 66,\n",
       " 'colors': 67,\n",
       " 'new': 68,\n",
       " 'looked': 69,\n",
       " 'at': 70,\n",
       " 'for': 71,\n",
       " 'were': 72,\n",
       " 'near': 73,\n",
       " 'voices': 74,\n",
       " 'even': 75,\n",
       " 'who': 76,\n",
       " 'worked': 77,\n",
       " 'across': 78,\n",
       " 'water': 79,\n",
       " 'flow': 80,\n",
       " 'rest': 81,\n",
       " 'anyone': 82,\n",
       " 'thoughts': 83,\n",
       " 'them': 84,\n",
       " 'time': 85,\n",
       " 'find': 86,\n",
       " 'peace': 87,\n",
       " 'fruits': 88,\n",
       " 'cooled': 89,\n",
       " 'hours': 90,\n",
       " 'tasks': 91,\n",
       " 'long': 92,\n",
       " 'evening': 93,\n",
       " 'night': 94,\n",
       " 'steps': 95,\n",
       " 'nothing': 96,\n",
       " 'fast': 97,\n",
       " 'loud': 98,\n",
       " 'passed': 99,\n",
       " 'through': 100,\n",
       " 'because': 101,\n",
       " 'understand': 102,\n",
       " 'sun': 103,\n",
       " 'up': 104,\n",
       " 'over': 105,\n",
       " 'morning': 106,\n",
       " 'everything': 107,\n",
       " 'look': 108,\n",
       " 'fresh': 109,\n",
       " 'opened': 110,\n",
       " 'doors': 111,\n",
       " 'out': 112,\n",
       " 'others': 113,\n",
       " 'prepared': 114,\n",
       " 'work': 115,\n",
       " 'tried': 116,\n",
       " 'keep': 117,\n",
       " 'pace': 118,\n",
       " 'so': 119,\n",
       " 'would': 120,\n",
       " 'not': 121,\n",
       " 'tired': 122,\n",
       " 'roads': 123,\n",
       " 'often': 124,\n",
       " 'point': 125,\n",
       " 'without': 126,\n",
       " 'any': 127,\n",
       " 'rush': 128,\n",
       " 'filled': 129,\n",
       " 'area': 130,\n",
       " 'peaceful': 131,\n",
       " 'few': 132,\n",
       " 'children': 133,\n",
       " 'played': 134,\n",
       " 'wide': 135,\n",
       " 'field': 136,\n",
       " 'ran': 137,\n",
       " 'circles': 138,\n",
       " 'laughed': 139,\n",
       " 'enjoyed': 140,\n",
       " 'moment': 141,\n",
       " 'lighter': 142,\n",
       " 'those': 143,\n",
       " 'hard': 144,\n",
       " 'smiled': 145,\n",
       " 'heard': 146,\n",
       " 'happy': 147,\n",
       " 'sounds': 148,\n",
       " 'wave': 149,\n",
       " 'there': 150,\n",
       " 'edge': 151,\n",
       " 'path': 152,\n",
       " 'brought': 153,\n",
       " 'grass': 154,\n",
       " 'beside': 155,\n",
       " 'let': 156,\n",
       " 'drift': 157,\n",
       " 'that': 158,\n",
       " 'movement': 159,\n",
       " 'helped': 160,\n",
       " 'minds': 161,\n",
       " 'coming': 162,\n",
       " 'needed': 163,\n",
       " 'never': 164,\n",
       " 'rushed': 165,\n",
       " 'its': 166,\n",
       " 'motion': 167,\n",
       " 'gound': 168,\n",
       " 'during': 169,\n",
       " 'daily': 170,\n",
       " 'picked': 171,\n",
       " 'plants': 172,\n",
       " 'tools': 173,\n",
       " 'goods': 174,\n",
       " 'spot': 175,\n",
       " 'task': 176,\n",
       " 'no': 177,\n",
       " 'need': 178,\n",
       " 'hurry': 179,\n",
       " 'stayed': 180,\n",
       " 'action': 181,\n",
       " 'seemed': 182,\n",
       " 'follow': 183,\n",
       " 'pattern': 184,\n",
       " 'everyone': 185,\n",
       " 'accepted': 186,\n",
       " 'problems': 187,\n",
       " 'solved': 188,\n",
       " 'hands': 189,\n",
       " 'began': 190,\n",
       " 'fade': 191,\n",
       " 'shifted': 192,\n",
       " 'into': 193,\n",
       " 'softer': 194,\n",
       " 'tone': 195,\n",
       " 'shade': 196,\n",
       " 'fell': 197,\n",
       " 'slowly': 198,\n",
       " 'finished': 199,\n",
       " 'forward': 200,\n",
       " 'outside': 201,\n",
       " 'homes': 202,\n",
       " 'watched': 203,\n",
       " 'change': 204,\n",
       " 'spoke': 205,\n",
       " 'about': 206,\n",
       " 'things': 207,\n",
       " 'weather': 208,\n",
       " 'food': 209,\n",
       " 'how': 210,\n",
       " 'had': 211,\n",
       " 'gone': 212,\n",
       " 'talking': 213,\n",
       " 'mixed': 214,\n",
       " 'cool': 215,\n",
       " 'safe': 216,\n",
       " 'dark': 217,\n",
       " 'found': 218,\n",
       " 'inside': 219,\n",
       " 'lay': 220,\n",
       " 'beds': 221,\n",
       " 'letting': 222,\n",
       " 'bodies': 223,\n",
       " 'down': 224,\n",
       " 'after': 225,\n",
       " 'grew': 226,\n",
       " 'still': 227,\n",
       " 'only': 228,\n",
       " 'live': 229,\n",
       " 'chance': 230}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fabc32ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "230"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d0f7aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(columns=[\"Input\",\"Output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "651bcc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence=tokenizer.texts_to_sequences(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86da01aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sen in sentence:\n",
    "    leng = len(sen)       # len is now the built-in function\n",
    "\n",
    "    for i in range(leng):\n",
    "        df = pd.concat([df, pd.DataFrame([{\"Input\": sen[0:i], \"Output\": sen[i]}])],ignore_index=True)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e7d8733",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.iloc[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85cc241e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1]</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1, 6]</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1, 6, 24]</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1, 6, 24, 34]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[1, 6, 24, 34, 2]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>[5, 40, 17, 15, 48, 2, 64, 68, 6, 20, 51, 47, ...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>[5, 40, 17, 15, 48, 2, 64, 68, 6, 20, 51, 47, ...</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>[5, 40, 17, 15, 48, 2, 64, 68, 6, 20, 51, 47, ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>[5, 40, 17, 15, 48, 2, 64, 68, 6, 20, 51, 47, ...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>[5, 40, 17, 15, 48, 2, 64, 68, 6, 20, 51, 47, ...</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>556 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Input Output\n",
       "1                                                  [1]      6\n",
       "2                                               [1, 6]     24\n",
       "3                                           [1, 6, 24]     34\n",
       "4                                       [1, 6, 24, 34]      2\n",
       "5                                    [1, 6, 24, 34, 2]      1\n",
       "..                                                 ...    ...\n",
       "552  [5, 40, 17, 15, 48, 2, 64, 68, 6, 20, 51, 47, ...     19\n",
       "553  [5, 40, 17, 15, 48, 2, 64, 68, 6, 20, 51, 47, ...     87\n",
       "554  [5, 40, 17, 15, 48, 2, 64, 68, 6, 20, 51, 47, ...      2\n",
       "555  [5, 40, 17, 15, 48, 2, 64, 68, 6, 20, 51, 47, ...     16\n",
       "556  [5, 40, 17, 15, 48, 2, 64, 68, 6, 20, 51, 47, ...     50\n",
       "\n",
       "[556 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5079c6",
   "metadata": {},
   "source": [
    "So we have coverted the text into int endoded arrays and got input and output as dataset. now we need to zero padd inputs to make them uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "02fe297f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df[\"Input\"]\n",
    "y=df[\"Output\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83d3ebdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.array(x)\n",
    "y=np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e69a071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_leng=[len(x) for x in x]\n",
    "max_len=max(seq_leng)\n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f621f27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=pad_sequences(x,maxlen=max_len,padding=\"pre\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "172d5986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(556, 23)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6f0599c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## total words in vocabulary\n",
    "vocab_size = x.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b244da2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.reshape(y,(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bffd1a14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6],\n",
       "       [24],\n",
       "       [34],\n",
       "       [2],\n",
       "       [1],\n",
       "       [12],\n",
       "       [25],\n",
       "       [8],\n",
       "       [3],\n",
       "       [13],\n",
       "       [2],\n",
       "       [26],\n",
       "       [53],\n",
       "       [5],\n",
       "       [8],\n",
       "       [1],\n",
       "       [18],\n",
       "       [54],\n",
       "       [55],\n",
       "       [27],\n",
       "       [19],\n",
       "       [95],\n",
       "       [2],\n",
       "       [96],\n",
       "       [20],\n",
       "       [97],\n",
       "       [35],\n",
       "       [98],\n",
       "       [3],\n",
       "       [36],\n",
       "       [14],\n",
       "       [28],\n",
       "       [1],\n",
       "       [29],\n",
       "       [56],\n",
       "       [1],\n",
       "       [57],\n",
       "       [2],\n",
       "       [1],\n",
       "       [58],\n",
       "       [59],\n",
       "       [3],\n",
       "       [60],\n",
       "       [30],\n",
       "       [61],\n",
       "       [37],\n",
       "       [99],\n",
       "       [100],\n",
       "       [1],\n",
       "       [38],\n",
       "       [62],\n",
       "       [39],\n",
       "       [5],\n",
       "       [40],\n",
       "       [1],\n",
       "       [15],\n",
       "       [41],\n",
       "       [63],\n",
       "       [101],\n",
       "       [64],\n",
       "       [6],\n",
       "       [20],\n",
       "       [42],\n",
       "       [4],\n",
       "       [102],\n",
       "       [21],\n",
       "       [1],\n",
       "       [103],\n",
       "       [43],\n",
       "       [104],\n",
       "       [1],\n",
       "       [14],\n",
       "       [65],\n",
       "       [105],\n",
       "       [1],\n",
       "       [66],\n",
       "       [2],\n",
       "       [1],\n",
       "       [67],\n",
       "       [7],\n",
       "       [1],\n",
       "       [106],\n",
       "       [11],\n",
       "       [107],\n",
       "       [108],\n",
       "       [109],\n",
       "       [2],\n",
       "       [68],\n",
       "       [22],\n",
       "       [5],\n",
       "       [110],\n",
       "       [9],\n",
       "       [111],\n",
       "       [2],\n",
       "       [69],\n",
       "       [112],\n",
       "       [70],\n",
       "       [1],\n",
       "       [44],\n",
       "       [29],\n",
       "       [113],\n",
       "       [114],\n",
       "       [9],\n",
       "       [115],\n",
       "       [71],\n",
       "       [1],\n",
       "       [6],\n",
       "       [2],\n",
       "       [116],\n",
       "       [4],\n",
       "       [117],\n",
       "       [3],\n",
       "       [16],\n",
       "       [118],\n",
       "       [119],\n",
       "       [10],\n",
       "       [120],\n",
       "       [121],\n",
       "       [23],\n",
       "       [122],\n",
       "       [8],\n",
       "       [17],\n",
       "       [54],\n",
       "       [1],\n",
       "       [123],\n",
       "       [72],\n",
       "       [18],\n",
       "       [2],\n",
       "       [1],\n",
       "       [57],\n",
       "       [24],\n",
       "       [45],\n",
       "       [5],\n",
       "       [124],\n",
       "       [55],\n",
       "       [28],\n",
       "       [46],\n",
       "       [125],\n",
       "       [4],\n",
       "       [47],\n",
       "       [126],\n",
       "       [127],\n",
       "       [128],\n",
       "       [3],\n",
       "       [13],\n",
       "       [16],\n",
       "       [48],\n",
       "       [129],\n",
       "       [1],\n",
       "       [130],\n",
       "       [2],\n",
       "       [17],\n",
       "       [48],\n",
       "       [11],\n",
       "       [1],\n",
       "       [6],\n",
       "       [23],\n",
       "       [131],\n",
       "       [3],\n",
       "       [132],\n",
       "       [133],\n",
       "       [134],\n",
       "       [73],\n",
       "       [3],\n",
       "       [135],\n",
       "       [38],\n",
       "       [136],\n",
       "       [10],\n",
       "       [137],\n",
       "       [8],\n",
       "       [138],\n",
       "       [139],\n",
       "       [27],\n",
       "       [49],\n",
       "       [74],\n",
       "       [2],\n",
       "       [140],\n",
       "       [31],\n",
       "       [18],\n",
       "       [141],\n",
       "       [9],\n",
       "       [50],\n",
       "       [11],\n",
       "       [1],\n",
       "       [12],\n",
       "       [23],\n",
       "       [142],\n",
       "       [2],\n",
       "       [75],\n",
       "       [143],\n",
       "       [76],\n",
       "       [77],\n",
       "       [144],\n",
       "       [145],\n",
       "       [21],\n",
       "       [10],\n",
       "       [146],\n",
       "       [1],\n",
       "       [147],\n",
       "       [148],\n",
       "       [17],\n",
       "       [15],\n",
       "       [50],\n",
       "       [65],\n",
       "       [78],\n",
       "       [1],\n",
       "       [6],\n",
       "       [51],\n",
       "       [3],\n",
       "       [26],\n",
       "       [149],\n",
       "       [150],\n",
       "       [24],\n",
       "       [3],\n",
       "       [19],\n",
       "       [52],\n",
       "       [70],\n",
       "       [1],\n",
       "       [151],\n",
       "       [7],\n",
       "       [1],\n",
       "       [38],\n",
       "       [62],\n",
       "       [1],\n",
       "       [79],\n",
       "       [25],\n",
       "       [8],\n",
       "       [3],\n",
       "       [44],\n",
       "       [2],\n",
       "       [45],\n",
       "       [152],\n",
       "       [2],\n",
       "       [1],\n",
       "       [26],\n",
       "       [30],\n",
       "       [7],\n",
       "       [1],\n",
       "       [80],\n",
       "       [153],\n",
       "       [81],\n",
       "       [4],\n",
       "       [82],\n",
       "       [76],\n",
       "       [32],\n",
       "       [73],\n",
       "       [37],\n",
       "       [22],\n",
       "       [5],\n",
       "       [32],\n",
       "       [33],\n",
       "       [1],\n",
       "       [154],\n",
       "       [155],\n",
       "       [1],\n",
       "       [79],\n",
       "       [2],\n",
       "       [156],\n",
       "       [9],\n",
       "       [83],\n",
       "       [157],\n",
       "       [10],\n",
       "       [20],\n",
       "       [158],\n",
       "       [1],\n",
       "       [16],\n",
       "       [159],\n",
       "       [7],\n",
       "       [1],\n",
       "       [52],\n",
       "       [160],\n",
       "       [84],\n",
       "       [44],\n",
       "       [9],\n",
       "       [161],\n",
       "       [39],\n",
       "       [5],\n",
       "       [40],\n",
       "       [162],\n",
       "       [63],\n",
       "       [21],\n",
       "       [10],\n",
       "       [163],\n",
       "       [34],\n",
       "       [85],\n",
       "       [1],\n",
       "       [52],\n",
       "       [164],\n",
       "       [165],\n",
       "       [2],\n",
       "       [166],\n",
       "       [13],\n",
       "       [167],\n",
       "       [11],\n",
       "       [37],\n",
       "       [42],\n",
       "       [71],\n",
       "       [82],\n",
       "       [4],\n",
       "       [86],\n",
       "       [87],\n",
       "       [1],\n",
       "       [88],\n",
       "       [33],\n",
       "       [1],\n",
       "       [168],\n",
       "       [72],\n",
       "       [89],\n",
       "       [169],\n",
       "       [1],\n",
       "       [49],\n",
       "       [90],\n",
       "       [5],\n",
       "       [77],\n",
       "       [33],\n",
       "       [170],\n",
       "       [91],\n",
       "       [22],\n",
       "       [171],\n",
       "       [88],\n",
       "       [28],\n",
       "       [18],\n",
       "       [172],\n",
       "       [22],\n",
       "       [59],\n",
       "       [173],\n",
       "       [2],\n",
       "       [22],\n",
       "       [25],\n",
       "       [15],\n",
       "       [174],\n",
       "       [28],\n",
       "       [46],\n",
       "       [175],\n",
       "       [4],\n",
       "       [47],\n",
       "       [31],\n",
       "       [176],\n",
       "       [24],\n",
       "       [14],\n",
       "       [2],\n",
       "       [177],\n",
       "       [46],\n",
       "       [20],\n",
       "       [1],\n",
       "       [178],\n",
       "       [4],\n",
       "       [179],\n",
       "       [1],\n",
       "       [12],\n",
       "       [180],\n",
       "       [36],\n",
       "       [2],\n",
       "       [31],\n",
       "       [181],\n",
       "       [182],\n",
       "       [4],\n",
       "       [183],\n",
       "       [3],\n",
       "       [60],\n",
       "       [80],\n",
       "       [85],\n",
       "       [25],\n",
       "       [8],\n",
       "       [3],\n",
       "       [45],\n",
       "       [184],\n",
       "       [2],\n",
       "       [185],\n",
       "       [186],\n",
       "       [17],\n",
       "       [13],\n",
       "       [53],\n",
       "       [7],\n",
       "       [41],\n",
       "       [75],\n",
       "       [21],\n",
       "       [18],\n",
       "       [187],\n",
       "       [43],\n",
       "       [5],\n",
       "       [188],\n",
       "       [84],\n",
       "       [27],\n",
       "       [19],\n",
       "       [83],\n",
       "       [2],\n",
       "       [16],\n",
       "       [189],\n",
       "       [21],\n",
       "       [1],\n",
       "       [49],\n",
       "       [14],\n",
       "       [7],\n",
       "       [1],\n",
       "       [29],\n",
       "       [190],\n",
       "       [4],\n",
       "       [191],\n",
       "       [1],\n",
       "       [6],\n",
       "       [192],\n",
       "       [193],\n",
       "       [3],\n",
       "       [194],\n",
       "       [195],\n",
       "       [1],\n",
       "       [12],\n",
       "       [89],\n",
       "       [2],\n",
       "       [3],\n",
       "       [92],\n",
       "       [196],\n",
       "       [197],\n",
       "       [78],\n",
       "       [1],\n",
       "       [66],\n",
       "       [5],\n",
       "       [198],\n",
       "       [199],\n",
       "       [9],\n",
       "       [91],\n",
       "       [2],\n",
       "       [69],\n",
       "       [200],\n",
       "       [4],\n",
       "       [1],\n",
       "       [34],\n",
       "       [90],\n",
       "       [7],\n",
       "       [1],\n",
       "       [93],\n",
       "       [39],\n",
       "       [32],\n",
       "       [201],\n",
       "       [9],\n",
       "       [202],\n",
       "       [2],\n",
       "       [203],\n",
       "       [1],\n",
       "       [29],\n",
       "       [204],\n",
       "       [67],\n",
       "       [10],\n",
       "       [205],\n",
       "       [8],\n",
       "       [14],\n",
       "       [74],\n",
       "       [206],\n",
       "       [15],\n",
       "       [207],\n",
       "       [51],\n",
       "       [1],\n",
       "       [208],\n",
       "       [1],\n",
       "       [209],\n",
       "       [10],\n",
       "       [11],\n",
       "       [35],\n",
       "       [210],\n",
       "       [1],\n",
       "       [6],\n",
       "       [211],\n",
       "       [212],\n",
       "       [1],\n",
       "       [19],\n",
       "       [30],\n",
       "       [7],\n",
       "       [213],\n",
       "       [214],\n",
       "       [27],\n",
       "       [1],\n",
       "       [215],\n",
       "       [12],\n",
       "       [11],\n",
       "       [1],\n",
       "       [93],\n",
       "       [23],\n",
       "       [216],\n",
       "       [2],\n",
       "       [36],\n",
       "       [61],\n",
       "       [1],\n",
       "       [26],\n",
       "       [217],\n",
       "       [7],\n",
       "       [94],\n",
       "       [43],\n",
       "       [8],\n",
       "       [5],\n",
       "       [218],\n",
       "       [81],\n",
       "       [10],\n",
       "       [32],\n",
       "       [219],\n",
       "       [35],\n",
       "       [220],\n",
       "       [33],\n",
       "       [15],\n",
       "       [221],\n",
       "       [222],\n",
       "       [9],\n",
       "       [223],\n",
       "       [13],\n",
       "       [224],\n",
       "       [225],\n",
       "       [1],\n",
       "       [92],\n",
       "       [6],\n",
       "       [1],\n",
       "       [12],\n",
       "       [226],\n",
       "       [227],\n",
       "       [2],\n",
       "       [228],\n",
       "       [1],\n",
       "       [14],\n",
       "       [30],\n",
       "       [7],\n",
       "       [1],\n",
       "       [58],\n",
       "       [56],\n",
       "       [1],\n",
       "       [94],\n",
       "       [17],\n",
       "       [13],\n",
       "       [2],\n",
       "       [16],\n",
       "       [41],\n",
       "       [11],\n",
       "       [31],\n",
       "       [6],\n",
       "       [23],\n",
       "       [42],\n",
       "       [4],\n",
       "       [229],\n",
       "       [5],\n",
       "       [40],\n",
       "       [17],\n",
       "       [15],\n",
       "       [48],\n",
       "       [2],\n",
       "       [64],\n",
       "       [68],\n",
       "       [6],\n",
       "       [20],\n",
       "       [51],\n",
       "       [47],\n",
       "       [230],\n",
       "       [4],\n",
       "       [86],\n",
       "       [19],\n",
       "       [87],\n",
       "       [2],\n",
       "       [16],\n",
       "       [50]], dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c029f2bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ebe4aa",
   "metadata": {},
   "source": [
    "Using OHE on output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e7bceb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe=OneHotEncoder(sparse_output=False)\n",
    "y=ohe.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7804b60b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(556, 230)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "488cc271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "230"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34abae93",
   "metadata": {},
   "source": [
    "So No of words = no of columns in output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79aad7e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Deep Learning\\.venv\\lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "input_l=x.shape[(1)]\n",
    "model=Sequential([\n",
    "    Embedding(input_dim=vocab_size+1,output_dim=100,input_length=input_l), ### there are 229 words and each OHEed x has 23 len\n",
    "    GRU(150), # each GRU cell will have 150 neurons in it(1 layer)\n",
    "    Dense(vocab_size,activation=\"softmax\") # 229 words so 229 classes\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "19c1fbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d5fa634d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                       │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru (\u001b[38;5;33mGRU\u001b[0m)                       │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "61463792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.0827 - loss: 5.4125\n",
      "Epoch 2/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.1007 - loss: 5.1235\n",
      "Epoch 3/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.1007 - loss: 4.9425\n",
      "Epoch 4/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.1007 - loss: 4.8579\n",
      "Epoch 5/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.1025 - loss: 4.8017\n",
      "Epoch 6/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.1313 - loss: 4.7271\n",
      "Epoch 7/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.1385 - loss: 4.6140\n",
      "Epoch 8/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.1475 - loss: 4.4773\n",
      "Epoch 9/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.1727 - loss: 4.2761\n",
      "Epoch 10/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.1763 - loss: 4.0851\n",
      "Epoch 11/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.1906 - loss: 3.8932\n",
      "Epoch 12/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.2032 - loss: 3.6933\n",
      "Epoch 13/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.2158 - loss: 3.4975\n",
      "Epoch 14/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.2500 - loss: 3.3006\n",
      "Epoch 15/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.2806 - loss: 3.1193\n",
      "Epoch 16/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.3183 - loss: 2.9278\n",
      "Epoch 17/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3489 - loss: 2.7479\n",
      "Epoch 18/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.3795 - loss: 2.5721\n",
      "Epoch 19/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.4245 - loss: 2.3897\n",
      "Epoch 20/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.4730 - loss: 2.2288\n",
      "Epoch 21/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5252 - loss: 2.0723\n",
      "Epoch 22/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5719 - loss: 1.9173\n",
      "Epoch 23/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6097 - loss: 1.7630\n",
      "Epoch 24/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6547 - loss: 1.6353\n",
      "Epoch 25/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6924 - loss: 1.5067\n",
      "Epoch 26/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7464 - loss: 1.3852\n",
      "Epoch 27/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7626 - loss: 1.2879\n",
      "Epoch 28/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7842 - loss: 1.1837\n",
      "Epoch 29/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8129 - loss: 1.0929\n",
      "Epoch 30/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8058 - loss: 1.0121\n",
      "Epoch 31/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8255 - loss: 0.9415\n",
      "Epoch 32/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8453 - loss: 0.8820\n",
      "Epoch 33/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8615 - loss: 0.8214\n",
      "Epoch 34/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8669 - loss: 0.7686\n",
      "Epoch 35/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8759 - loss: 0.7213\n",
      "Epoch 36/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8849 - loss: 0.6817\n",
      "Epoch 37/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8903 - loss: 0.6439\n",
      "Epoch 38/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8903 - loss: 0.6105\n",
      "Epoch 39/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8903 - loss: 0.5828\n",
      "Epoch 40/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8975 - loss: 0.5619\n",
      "Epoch 41/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9011 - loss: 0.5354\n",
      "Epoch 42/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8957 - loss: 0.5153\n",
      "Epoch 43/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8993 - loss: 0.4942\n",
      "Epoch 44/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8993 - loss: 0.4793\n",
      "Epoch 45/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9029 - loss: 0.4601\n",
      "Epoch 46/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9065 - loss: 0.4478\n",
      "Epoch 47/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9029 - loss: 0.4339\n",
      "Epoch 48/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9047 - loss: 0.4251\n",
      "Epoch 49/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8993 - loss: 0.4129\n",
      "Epoch 50/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9029 - loss: 0.4037\n",
      "Epoch 51/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8957 - loss: 0.3947\n",
      "Epoch 52/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9011 - loss: 0.3904\n",
      "Epoch 53/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9101 - loss: 0.3776\n",
      "Epoch 54/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9011 - loss: 0.3722\n",
      "Epoch 55/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9029 - loss: 0.3685\n",
      "Epoch 56/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9029 - loss: 0.3613\n",
      "Epoch 57/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9011 - loss: 0.3568\n",
      "Epoch 58/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9029 - loss: 0.3514\n",
      "Epoch 59/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9065 - loss: 0.3485\n",
      "Epoch 60/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9011 - loss: 0.3408\n",
      "Epoch 61/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9029 - loss: 0.3381\n",
      "Epoch 62/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9047 - loss: 0.3334\n",
      "Epoch 63/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9011 - loss: 0.3298\n",
      "Epoch 64/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9065 - loss: 0.3270\n",
      "Epoch 65/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9029 - loss: 0.3285\n",
      "Epoch 66/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9029 - loss: 0.3221\n",
      "Epoch 67/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9011 - loss: 0.3197\n",
      "Epoch 68/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8975 - loss: 0.3176\n",
      "Epoch 69/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9011 - loss: 0.3153\n",
      "Epoch 70/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8993 - loss: 0.3132\n",
      "Epoch 71/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9047 - loss: 0.3115\n",
      "Epoch 72/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9065 - loss: 0.3069\n",
      "Epoch 73/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9047 - loss: 0.3079\n",
      "Epoch 74/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8975 - loss: 0.3115\n",
      "Epoch 75/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9029 - loss: 0.3051\n",
      "Epoch 76/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9011 - loss: 0.3020\n",
      "Epoch 77/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8993 - loss: 0.3009\n",
      "Epoch 78/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9029 - loss: 0.2990\n",
      "Epoch 79/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8993 - loss: 0.2990\n",
      "Epoch 80/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9047 - loss: 0.2961\n",
      "Epoch 81/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8921 - loss: 0.2966\n",
      "Epoch 82/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8993 - loss: 0.2980\n",
      "Epoch 83/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9065 - loss: 0.2920\n",
      "Epoch 84/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9029 - loss: 0.2927\n",
      "Epoch 85/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9065 - loss: 0.2902\n",
      "Epoch 86/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9011 - loss: 0.2936\n",
      "Epoch 87/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9011 - loss: 0.2921\n",
      "Epoch 88/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8993 - loss: 0.2906\n",
      "Epoch 89/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9029 - loss: 0.2908\n",
      "Epoch 90/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8957 - loss: 0.2927\n",
      "Epoch 91/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8939 - loss: 0.2906\n",
      "Epoch 92/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8993 - loss: 0.2859\n",
      "Epoch 93/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9029 - loss: 0.2824\n",
      "Epoch 94/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9011 - loss: 0.2845\n",
      "Epoch 95/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9047 - loss: 0.2819\n",
      "Epoch 96/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8993 - loss: 0.2851\n",
      "Epoch 97/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9011 - loss: 0.2833\n",
      "Epoch 98/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9029 - loss: 0.2828\n",
      "Epoch 99/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9029 - loss: 0.2828\n",
      "Epoch 100/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9083 - loss: 0.2814\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1cb50dabc70>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x,y,epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a33ffd6",
   "metadata": {},
   "source": [
    "Predicting a word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8084e5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "word=\"Each new day i want \"\n",
    "## tokeizing the text\n",
    "word_token=tokenizer.texts_to_sequences([word])[0]\n",
    "## paddeing\n",
    "word_pad=pad_sequences([word_token],maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "78243f49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 1,\n",
       " 'and': 2,\n",
       " 'a': 3,\n",
       " 'to': 4,\n",
       " 'people': 5,\n",
       " 'day': 6,\n",
       " 'of': 7,\n",
       " 'in': 8,\n",
       " 'their': 9,\n",
       " 'they': 10,\n",
       " 'made': 11,\n",
       " 'air': 12,\n",
       " 'slow': 13,\n",
       " 'light': 14,\n",
       " 'simple': 15,\n",
       " 'steady': 16,\n",
       " 'this': 17,\n",
       " 'small': 18,\n",
       " 'calm': 19,\n",
       " 'felt': 20,\n",
       " 'when': 21,\n",
       " 'some': 22,\n",
       " 'feel': 23,\n",
       " 'was': 24,\n",
       " 'moved': 25,\n",
       " 'soft': 26,\n",
       " 'with': 27,\n",
       " 'from': 28,\n",
       " 'sky': 29,\n",
       " 'sound': 30,\n",
       " 'every': 31,\n",
       " 'sat': 32,\n",
       " 'on': 33,\n",
       " 'quiet': 34,\n",
       " 'or': 35,\n",
       " 'warm': 36,\n",
       " 'it': 37,\n",
       " 'open': 38,\n",
       " 'many': 39,\n",
       " 'liked': 40,\n",
       " 'life': 41,\n",
       " 'easy': 42,\n",
       " 'came': 43,\n",
       " 'clear': 44,\n",
       " 'smooth': 45,\n",
       " 'one': 46,\n",
       " 'another': 47,\n",
       " 'rhythm': 48,\n",
       " 'bright': 49,\n",
       " 'joy': 50,\n",
       " 'like': 51,\n",
       " 'stream': 52,\n",
       " 'way': 53,\n",
       " 'place': 54,\n",
       " 'walked': 55,\n",
       " 'touched': 56,\n",
       " 'ground': 57,\n",
       " 'wind': 58,\n",
       " 'carried': 59,\n",
       " 'gentle': 60,\n",
       " 'as': 61,\n",
       " 'space': 62,\n",
       " 'here': 63,\n",
       " 'each': 64,\n",
       " 'spread': 65,\n",
       " 'fields': 66,\n",
       " 'colors': 67,\n",
       " 'new': 68,\n",
       " 'looked': 69,\n",
       " 'at': 70,\n",
       " 'for': 71,\n",
       " 'were': 72,\n",
       " 'near': 73,\n",
       " 'voices': 74,\n",
       " 'even': 75,\n",
       " 'who': 76,\n",
       " 'worked': 77,\n",
       " 'across': 78,\n",
       " 'water': 79,\n",
       " 'flow': 80,\n",
       " 'rest': 81,\n",
       " 'anyone': 82,\n",
       " 'thoughts': 83,\n",
       " 'them': 84,\n",
       " 'time': 85,\n",
       " 'find': 86,\n",
       " 'peace': 87,\n",
       " 'fruits': 88,\n",
       " 'cooled': 89,\n",
       " 'hours': 90,\n",
       " 'tasks': 91,\n",
       " 'long': 92,\n",
       " 'evening': 93,\n",
       " 'night': 94,\n",
       " 'steps': 95,\n",
       " 'nothing': 96,\n",
       " 'fast': 97,\n",
       " 'loud': 98,\n",
       " 'passed': 99,\n",
       " 'through': 100,\n",
       " 'because': 101,\n",
       " 'understand': 102,\n",
       " 'sun': 103,\n",
       " 'up': 104,\n",
       " 'over': 105,\n",
       " 'morning': 106,\n",
       " 'everything': 107,\n",
       " 'look': 108,\n",
       " 'fresh': 109,\n",
       " 'opened': 110,\n",
       " 'doors': 111,\n",
       " 'out': 112,\n",
       " 'others': 113,\n",
       " 'prepared': 114,\n",
       " 'work': 115,\n",
       " 'tried': 116,\n",
       " 'keep': 117,\n",
       " 'pace': 118,\n",
       " 'so': 119,\n",
       " 'would': 120,\n",
       " 'not': 121,\n",
       " 'tired': 122,\n",
       " 'roads': 123,\n",
       " 'often': 124,\n",
       " 'point': 125,\n",
       " 'without': 126,\n",
       " 'any': 127,\n",
       " 'rush': 128,\n",
       " 'filled': 129,\n",
       " 'area': 130,\n",
       " 'peaceful': 131,\n",
       " 'few': 132,\n",
       " 'children': 133,\n",
       " 'played': 134,\n",
       " 'wide': 135,\n",
       " 'field': 136,\n",
       " 'ran': 137,\n",
       " 'circles': 138,\n",
       " 'laughed': 139,\n",
       " 'enjoyed': 140,\n",
       " 'moment': 141,\n",
       " 'lighter': 142,\n",
       " 'those': 143,\n",
       " 'hard': 144,\n",
       " 'smiled': 145,\n",
       " 'heard': 146,\n",
       " 'happy': 147,\n",
       " 'sounds': 148,\n",
       " 'wave': 149,\n",
       " 'there': 150,\n",
       " 'edge': 151,\n",
       " 'path': 152,\n",
       " 'brought': 153,\n",
       " 'grass': 154,\n",
       " 'beside': 155,\n",
       " 'let': 156,\n",
       " 'drift': 157,\n",
       " 'that': 158,\n",
       " 'movement': 159,\n",
       " 'helped': 160,\n",
       " 'minds': 161,\n",
       " 'coming': 162,\n",
       " 'needed': 163,\n",
       " 'never': 164,\n",
       " 'rushed': 165,\n",
       " 'its': 166,\n",
       " 'motion': 167,\n",
       " 'gound': 168,\n",
       " 'during': 169,\n",
       " 'daily': 170,\n",
       " 'picked': 171,\n",
       " 'plants': 172,\n",
       " 'tools': 173,\n",
       " 'goods': 174,\n",
       " 'spot': 175,\n",
       " 'task': 176,\n",
       " 'no': 177,\n",
       " 'need': 178,\n",
       " 'hurry': 179,\n",
       " 'stayed': 180,\n",
       " 'action': 181,\n",
       " 'seemed': 182,\n",
       " 'follow': 183,\n",
       " 'pattern': 184,\n",
       " 'everyone': 185,\n",
       " 'accepted': 186,\n",
       " 'problems': 187,\n",
       " 'solved': 188,\n",
       " 'hands': 189,\n",
       " 'began': 190,\n",
       " 'fade': 191,\n",
       " 'shifted': 192,\n",
       " 'into': 193,\n",
       " 'softer': 194,\n",
       " 'tone': 195,\n",
       " 'shade': 196,\n",
       " 'fell': 197,\n",
       " 'slowly': 198,\n",
       " 'finished': 199,\n",
       " 'forward': 200,\n",
       " 'outside': 201,\n",
       " 'homes': 202,\n",
       " 'watched': 203,\n",
       " 'change': 204,\n",
       " 'spoke': 205,\n",
       " 'about': 206,\n",
       " 'things': 207,\n",
       " 'weather': 208,\n",
       " 'food': 209,\n",
       " 'how': 210,\n",
       " 'had': 211,\n",
       " 'gone': 212,\n",
       " 'talking': 213,\n",
       " 'mixed': 214,\n",
       " 'cool': 215,\n",
       " 'safe': 216,\n",
       " 'dark': 217,\n",
       " 'found': 218,\n",
       " 'inside': 219,\n",
       " 'lay': 220,\n",
       " 'beds': 221,\n",
       " 'letting': 222,\n",
       " 'bodies': 223,\n",
       " 'down': 224,\n",
       " 'after': 225,\n",
       " 'grew': 226,\n",
       " 'still': 227,\n",
       " 'only': 228,\n",
       " 'live': 229,\n",
       " 'chance': 230}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0665a189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 246ms/step\n",
      "It feel like slow\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "It feel like slow the\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "It feel like slow the from\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "It feel like slow the from hands\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "text = \"It feel like\"\n",
    "for i in range(4):\n",
    "    word_token = tokenizer.texts_to_sequences([text])[0]\n",
    "    word_pad = pad_sequences([word_token], maxlen=max_len,padding=\"pre\")\n",
    "    predict = model.predict(word_pad)\n",
    "    index = np.argmax(predict)\n",
    "    for word_, indx in tokenizer.word_index.items():\n",
    "        if indx==index:\n",
    "            text = text + \" \" + word_\n",
    "            print(text)\n",
    "            time.sleep(3)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f30a9dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "The people liked sat\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "The people liked sat sat\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step\n",
      "The people liked sat sat soft\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "The people liked sat sat soft hours\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "The people liked sat sat soft hours beds\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "The people liked sat sat soft hours beds here\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "The people liked sat sat soft hours beds here felt\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "text = \"The people liked\"\n",
    "\n",
    "for i in range(10):\n",
    "  # tokenize\n",
    "  token_text = tokenizer.texts_to_sequences([text])[0]\n",
    "  # padding\n",
    "  padded_token_text = pad_sequences([token_text], maxlen=56, padding='pre')\n",
    "  # predict\n",
    "  pos = np.argmax(model.predict(padded_token_text))\n",
    "\n",
    "  for word,index in tokenizer.word_index.items():\n",
    "    if index == pos:\n",
    "      text = text + \" \" + word\n",
    "      print(text)\n",
    "      time.sleep(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-learning (3.10.18)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
